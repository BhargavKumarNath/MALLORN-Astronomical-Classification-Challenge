{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d51d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import warnings\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af200d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Lightcurves: 100%|██████████| 20/20 [00:00<00:00, 28.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data loaded.\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../data/'\n",
    "train_log_df = pd.read_csv(os.path.join(DATA_PATH, 'train_log.csv'))\n",
    "test_log_df = pd.read_csv(os.path.join(DATA_PATH, 'test_log.csv'))\n",
    "\n",
    "# Load all lightcurve data (both train and test)\n",
    "full_lc_df = []\n",
    "for split_folder in tqdm(train_log_df['split'].unique(), desc=\"Loading Lightcurves\"):\n",
    "    train_path = os.path.join(DATA_PATH, split_folder, 'train_full_lightcurves.csv')\n",
    "    test_path = os.path.join(DATA_PATH, split_folder, 'test_full_lightcurves.csv')\n",
    "    full_lc_df.append(pd.read_csv(train_path))\n",
    "    full_lc_df.append(pd.read_csv(test_path))\n",
    "full_lc_df = pd.concat(full_lc_df).dropna(subset=['Flux'])\n",
    "print(\"All data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15963ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features per filter: 100%|██████████| 6/6 [11:51<00:00, 118.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsfresh feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering with tsfresh (on ALL data)\n",
    "band_features = []\n",
    "for f in tqdm(full_lc_df['Filter'].unique(), desc=\"Extracting features per filter\"):\n",
    "    subset = full_lc_df[full_lc_df['Filter'] == f][['object_id', 'Time (MJD)', 'Flux']].copy()\n",
    "    subset.columns = ['id', 'time', 'value']\n",
    "    \n",
    "    feats = extract_features(\n",
    "        subset, column_id='id', column_sort='time',\n",
    "        default_fc_parameters=EfficientFCParameters(),\n",
    "        disable_progressbar=True, n_jobs=4\n",
    "    )\n",
    "    feats.columns = [f\"{col}_{f}\" for col in feats.columns]\n",
    "    band_features.append(feats)\n",
    "\n",
    "extracted_features = pd.concat(band_features, axis=1)\n",
    "impute(extracted_features)\n",
    "print(\"tsfresh feature extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980e707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing Train and Test Sets ---\n",
      "Performing feature selection...\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Prepare Train and Test Sets ---\n",
    "print(\"\\n--- Preparing Train and Test Sets ---\")\n",
    "train_ids = train_log_df['object_id'].unique()\n",
    "test_ids = test_log_df['object_id'].unique()\n",
    "train_features = extracted_features[extracted_features.index.isin(train_ids)]\n",
    "test_features = extracted_features[extracted_features.index.isin(test_ids)]\n",
    "y = train_log_df.set_index('object_id').loc[train_features.index]['target']\n",
    "\n",
    "print(\"Performing feature selection...\")\n",
    "relevant_feature_cols = select_features(train_features, y, fdr_level=0.005).columns\n",
    "train_features = train_features[relevant_feature_cols]\n",
    "test_features = test_features[relevant_feature_cols]\n",
    "\n",
    "train_full = train_features.merge(train_log_df[['object_id', 'Z', 'EBV']], left_index=True, right_on='object_id').set_index('object_id')\n",
    "test_full = test_features.merge(test_log_df[['object_id', 'Z', 'EBV']], left_index=True, right_on='object_id').set_index('object_id')\n",
    "train_full, test_full = train_full.align(test_full, join='left', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test sets are ready.\n"
     ]
    }
   ],
   "source": [
    "train_full.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_full.columns]\n",
    "test_full.columns = train_full.columns # Ensure test columns match exactly\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_full)\n",
    "X_test = scaler.transform(test_full)\n",
    "X_train = pd.DataFrame(X_train, columns=train_full.columns, index=train_full.index)\n",
    "X_test = pd.DataFrame(X_test, columns=test_full.columns, index=test_full.index)\n",
    "print(\"Train and test sets are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606eefd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Finding Optimal Threshold with Cross-Validation ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Finding Optimal Threshold with Cross-Validation ---\")\n",
    "best_params = {\n",
    "    'learning_rate': 0.0361, 'num_leaves': 120, 'max_depth': 11, 'min_child_samples': 80,\n",
    "    'subsample': 0.5577, 'colsample_bytree': 0.5736, 'reg_alpha': 0.3158, 'reg_lambda': 0.3171,\n",
    "    'objective': 'binary', 'metric': 'binary_logloss', 'boosting_type': 'gbdt', 'n_estimators': 2000,\n",
    "    'device': 'gpu', 'verbose': -1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cec021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined Optimal Threshold: 0.2733\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "thresholds_list = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y)):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_val_fold, y_val_fold = X_train.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    pos_count = y_train_fold.sum()\n",
    "    neg_count = len(y_train_fold) - pos_count\n",
    "    best_params['scale_pos_weight'] = neg_count / pos_count if pos_count > 0 else 1\n",
    "\n",
    "    model = lgb.LGBMClassifier(**best_params)\n",
    "    model.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)],\n",
    "              eval_metric='f1', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "    val_preds_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "    thresholds = np.linspace(0.01, 0.99, 100)\n",
    "    f1_values = [f1_score(y_val_fold, (val_preds_proba > t).astype(int)) for t in thresholds]\n",
    "    best_threshold = thresholds[np.argmax(f1_values)]\n",
    "    thresholds_list.append(best_threshold)\n",
    "\n",
    "OPTIMAL_THRESHOLD = np.mean(thresholds_list)\n",
    "print(f\"Determined Optimal Threshold: {OPTIMAL_THRESHOLD:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49904da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Final Model and Generating Predictions ---\n",
      "Predictions generated.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(\"\\n--- Training Final Model and Generating Predictions ---\")\n",
    "pos_count = y.sum()\n",
    "neg_count = len(y) - pos_count\n",
    "best_params['scale_pos_weight'] = neg_count / pos_count if pos_count > 0 else 1\n",
    "\n",
    "final_model = lgb.LGBMClassifier(**best_params)\n",
    "final_model.fit(X_train, y)\n",
    "test_predictions_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "test_predictions = (test_predictions_proba > OPTIMAL_THRESHOLD).astype(int)\n",
    "print(\"Predictions generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a2b15d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Submission File ---\n",
      "Submission file 'submission.csv' created successfully!\n",
      "\n",
      "--- Final Submission Head ---\n",
      "                object_id  prediction\n",
      "0    Dornhoth_adar_imrath           0\n",
      "1    Dornhoth_celeb_achad           0\n",
      "2    Dornhoth_firion_fern           0\n",
      "3      Dornhoth_glae_aras           1\n",
      "4  Dornhoth_lain_tinuviel           1\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Create and Save Submission File ---\n",
    "print(\"\\n--- Creating Submission File ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    'object_id': X_test.index,\n",
    "    'prediction': test_predictions\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' created successfully!\")\n",
    "print(\"\\n--- Final Submission Head ---\")\n",
    "print(submission_df.head())\n",
    "print(\"-\" * 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a19eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
